{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Brain Segmentation with Keras\n",
    "\n",
    "## MAIN 2019 Educational Course \n",
    "\n",
    "### Thomas Funck\n",
    "\n",
    "### McGill University\n",
    "\n",
    "### **Contact**: email: [tffunck@gmail.com](mailto:tffunck@gmail.com) , Twitter: [@tffunck\\](https://twitter.com/tffunck)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring basic options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minc_keras import create_dir_verbose\n",
    "from utils import *\n",
    "\n",
    "### Set input and label string\n",
    "input_str='pet.mnc' \n",
    "label_str='dtissue.mnc'\n",
    "\n",
    "### Set filename for .csv that will store data frame \n",
    "images_fn='data.csv'\n",
    "\n",
    "### Set source directory from which data will be read\n",
    "source_dir=\"/data1/users/tfunck/pet/data_ses/\"\n",
    "\n",
    "### Set the target directory where output results will be saved\n",
    "target_dir=\"/data1/users/tfunck/pet/results\"\n",
    "\n",
    "### Set raiots for train/validation/test\n",
    "ratios=[0.7,0.15]\n",
    "\n",
    "### By default we set clobber to False so that we don't overwrite existing files\n",
    "### Feel free to change if needed\n",
    "clobber=True\n",
    "\n",
    "### Size of batches that will be passed to model. The default 2 makes it easy\n",
    "batch_size=2\n",
    "\n",
    "### Image dimensions. We are slicing the 3D images into 2D slices. This serves to augment the data\n",
    "### and make training faster\n",
    "image_dim=2\n",
    "\n",
    "### Output activation function\n",
    "activation_output=\"softmax\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create output directories\n",
    "### This is just a little housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create output directories to save results\n",
    "data_dir = target_dir + os.sep + 'data'+os.sep\n",
    "report_dir = target_dir+os.sep+'report'+os.sep\n",
    "train_dir = target_dir+os.sep+'predict'+os.sep+'train'+os.sep\n",
    "test_dir = target_dir+os.sep+'predict'+os.sep+'test'+os.sep\n",
    "validate_dir = target_dir+os.sep+'predict'+os.sep+'validate'+os.sep\n",
    "model_dir=target_dir+os.sep+'model'\n",
    "\n",
    "create_dir_verbose(train_dir)\n",
    "create_dir_verbose(test_dir)\n",
    "create_dir_verbose(validate_dir)\n",
    "create_dir_verbose(data_dir)\n",
    "create_dir_verbose(report_dir) \n",
    "create_dir_verbose(model_dir)   \n",
    "\n",
    "### Set filename for .csv file that will contain info about input images\n",
    "images_fn = set_model_name(images_fn, report_dir, '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize input and label images into train/validate/test splits\n",
    "#### One of the hard parts of doing deep learning in practice is organizing your data.\n",
    "#### The following section is a bit of complicated because it involves organizing the input and label files into \n",
    "#### a data frame and assigning them to a train/validate/test splits.\n",
    "#### ***You can skip this if you're primarily interested in how to build a network.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : expected/real ratio = 70.00 / 70.29\n",
      "validate : expected/real ratio = 15.00 / 15.22\n",
      "Saving train images: 180 / 194\r"
     ]
    }
   ],
   "source": [
    "    from prepare_data import *\n",
    "    from set_images import *\n",
    "    ext='mnc' #default file extension is mnc for MINC files\n",
    "    ################\n",
    "    # Prepare Data #\n",
    "    ################\n",
    "    data={}\n",
    "    ### 0) Setup file names and output directories\n",
    "    data[\"train_x_fn\"] = data_dir + os.sep + 'train_x'\n",
    "    data[\"train_y_fn\"] = data_dir + os.sep + 'train_y'\n",
    "    data[\"validate_x_fn\"] = data_dir + os.sep + 'validate_x'\n",
    "    data[\"validate_y_fn\"] = data_dir + os.sep + 'validate_y'\n",
    "    data[\"test_x_fn\"] = data_dir + os.sep + 'test_x'\n",
    "    data[\"test_y_fn\"] = data_dir + os.sep + 'test_y'\n",
    "    \n",
    "    ### 1) Organize inputs into a data frame, match each PET image with label image\n",
    "    if not exists(images_fn) or clobber:\n",
    "        ### set_images is a very important function that will find all the PET images and their\n",
    "        ### corresponding labelled images from source_dir. This function uses <input_str> and <label_str>\n",
    "        ### to identify which files are inputs and labeles, respectively. The images use the BIDS file format\n",
    "        ### where subject, session, task, radiotracer are specificied in the filename. These variables are parsed\n",
    "        ### from the filenames and also stored in the data frame. \n",
    "        ### set_images will also split the images into training, validation, and test subsets\n",
    "        \n",
    "        ##############\n",
    "        # Set Images #\n",
    "        ##############\n",
    "        # 1 - gathering information (parsing the source directory)\n",
    "        subject_dirs, pet_list, names = gather_dirs(source_dir, input_str, ext )\n",
    "    \n",
    "        # 2 - checking for potential errors\n",
    "        if len(names) == 0:\n",
    "            print_error_nosubject(source_dir)\n",
    "        if sum(ratios) > 1.:\n",
    "            print_error_nosumone(ratios)\n",
    "    \n",
    "        # 3 - creating an empty directory of dataframes, then filling it.\n",
    "        dfd = {}\n",
    "        for name in names:\n",
    "            data_subject = process(name, source_dir, pet_list, label_str, ext)\n",
    "            #data_subject = process(name, source_dir, pet_list, t1_list, label_str, ext)\n",
    "            if not data_subject == 1: dfd[name] = pd.DataFrame(data_subject)  # formerly subject_df\n",
    "            \n",
    "        # 4 - concatenation of the dict of df to a single df\n",
    "        out = create_out(dfd)\n",
    "        \n",
    "        # 5 - attributing a train/validate/test category for all subject\n",
    "        # By setting the <category_class> to \"radiotracer\", the function <attribute_category> will attempt to split\n",
    "        # the amount of subjects for each radiotracer evenly into train/validate/test splits\n",
    "        if \"radiotracer\" in out.columns : category_class=\"radiotracer\" \n",
    "        else : category_class=\"task\" \n",
    "            \n",
    "        ### <attribute_category> will divide the subjects into train/validate/test splits, making sure that \n",
    "        ### if there are multiple scans from the same subject that they are all in the same split. For example,\n",
    "        ### you don't want the FDOPA scan for subject 01 to be in the train split and the FDG scan for subject\n",
    "        ### 01 in the validate split.\n",
    "        attribute_category(out, 'train',category_class, ratios[0])\n",
    "        attribute_category(out, 'validate',category_class, ratios[1])\n",
    "        out.category.loc[ out.category==\"unknown\" ] = \"test\"\n",
    "            \n",
    "        #5.5 Set the number of valid samples per image (some samples exluded because they contain no information)\n",
    "        set_valid_samples(out)\n",
    "\n",
    "        # 6 - export and return\n",
    "        out.to_csv(images_fn, index=False)\n",
    "        \n",
    "    else: \n",
    "        images = pd.read_csv(images_fn)\n",
    "            \n",
    "    ### 2) Split images into training and validate data frames\n",
    "    ###\n",
    "    train_images = images[images['category']=='train'].reset_index()\n",
    "    validate_images = images[images['category']=='validate'].reset_index()\n",
    "    test_images = images[images['category']=='test'].reset_index()\n",
    "    train_valid_samples = train_images.valid_samples.values.sum()  \n",
    "    validate_valid_samples  =  validate_images.valid_samples.values.sum()\n",
    "\n",
    "    ### 3) Get spatial dimensions of images \n",
    "    data[\"image_dim\"] = get_image_dim(images.iloc[0].label)\n",
    "\n",
    "    ### 4) Set up dimensions of data tensors to be used for training and validateing. all of the\n",
    "    if not exists(data[\"train_x_fn\"] + '.npy') or not exists( data[\"train_y_fn\"] + '.npy') or clobber:\n",
    "        feature_extraction(train_images, data['image_dim'], data[\"train_x_fn\"], data[\"train_y_fn\"], data_dir, clobber)\n",
    "    if not exists(data[\"validate_x_fn\"] + '.npy') or not exists(data[\"validate_y_fn\"] + '.npy') or clobber:\n",
    "        feature_extraction(validate_images, data['image_dim'], data[\"validate_x_fn\"], data[\"validate_y_fn\"], data_dir, clobber)\n",
    "    if not exists(data[\"test_x_fn\"] + '.npy') or not exists(data[\"test_y_fn\"] + '.npy') or clobber:\n",
    "        feature_extraction(validate_images, data['image_dim'], prepare_data[\"test_x_fn\"], data[\"test_y_fn\"], data_dir, clobber)\n",
    "    data[\"batch_size\"] = adjust_batch_size(train_valid_samples, validate_valid_samples, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a U-NET in Keras\n",
    "\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/unet.png?raw=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ### 1) Define architecture of neural network\n",
    "    Y_validate=np.load(data[\"validate_y_fn\"]+'.npy')\n",
    "    nlabels=len(np.unique(Y_validate))#Number of unique labels in the labeled images\n",
    "    \n",
    "    img_rows=image_dim[1]\n",
    "    img_cols=image_dim[2]\n",
    "    nMLP=16\n",
    "    nRshp=int(sqrt(nMLP))\n",
    "    nUpSm=int(image_dim[0]/nRshp)\n",
    "    image = Input(shape=(image_dim[1], image_dim[2],1))\n",
    "    \n",
    "    BN1 = BatchNormalization()(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    conv1 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(BN1)\n",
    "    conv1 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    conv2 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(pool1)\n",
    "    conv2 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    conv3 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(pool2)\n",
    "    conv3 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    conv4 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(pool3)\n",
    "    conv4 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    conv5 = Convolution2D(512, 3, 3, activation='relu', border_mode='same')(pool4)\n",
    "    conv5 = Convolution2D(512, 3, 3, activation='relu', border_mode='same')(conv5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    up6 = merge([UpSampling2D(size=(2, 2))(conv5), conv4], mode='concat', concat_axis=3)\n",
    "    conv6 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(up6)\n",
    "    conv6 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(conv6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    conv6_up = UpSampling2D(size=(2, 2))(conv6)\n",
    "    conv6_pad = ZeroPadding2D( ((1,0),(1,0)) )(conv6_up)\n",
    "    up7 = merge([conv6_pad, conv3], mode='concat', concat_axis=3)\n",
    "    conv7 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(up7)\n",
    "    conv7 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(conv7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    up8 = merge([UpSampling2D(size=(2, 2))(conv7), conv2], mode='concat', concat_axis=3)\n",
    "    conv8 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(up8)\n",
    "    conv8 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(conv8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    up9 = merge([UpSampling2D(size=(2, 2))(conv8), conv1], mode='concat', concat_axis=3)\n",
    "    conv9 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(up9)\n",
    "    conv9 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(conv9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    conv10 = Convolution2D(nlabels, 1, 1, activation=activation)(conv9)\n",
    "\n",
    "    model = keras.models.Model(input=[image], output=conv10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2) Train network on data\n",
    "model_fn =set_model_name(model_fn, model_dir)\n",
    "history_fn = splitext(model_fn)[0] + '_history.json'\n",
    "\n",
    "print( 'Model:', model_fn)\n",
    "if not exists(model_fn) or clobber:\n",
    "#If model_fn does not exist, or user wishes to write over (clobber) existing model\n",
    "#then train a new model and save it\n",
    "    X_train=np.load(data[\"train_x_fn\"]+'.npy')\n",
    "    Y_train=np.load(data[\"train_y_fn\"]+'.npy')\n",
    "    X_validate=np.load(data[\"validate_x_fn\"]+'.npy')\n",
    "     model,history = compile_and_run(model, model_fn, history_fn, X_train,  Y_train, X_validate,  Y_validate, nb_epoch, nlabels, loss=loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ### 3) Evaluate model on test data\n",
    "    model = load_model(model_fn)\n",
    "    X_test=np.load(data[\"test_x_fn\"]+'.npy')\n",
    "    Y_test=np.load(data[\"test_y_fn\"]+'.npy')\n",
    "    if loss in categorical_functions :\n",
    "        Y_test=to_categorical(Y_test)\n",
    "    test_score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "    print('Test: Loss=', test_score[0], 'Metric=', test_score[1])\n",
    "    #np.savetxt(report_dir+os.sep+'model_evaluate.csv', np.array(test_score) )\n",
    "\n",
    "    ### 4) Produce prediction\n",
    "    #predict(model_fn, validate_dir, data_dir, images_fn, images_to_predict=images_to_predict, category=\"validate\", verbose=verbose)\n",
    "    #predict(model_fn, train_dir, data_dir, images_fn, images_to_predict=images_to_predict, category=\"train\", verbose=verbose)\n",
    "    predict(model_fn, test_dir, data_dir, images_fn, loss, images_to_predict=images_to_predict, category=\"test\", verbose=verbose)\n",
    "    plot_loss(metric, history_fn, model_fn, report_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
