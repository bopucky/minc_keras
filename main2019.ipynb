{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Brain Segmentation with Keras\n",
    "\n",
    "## MAIN 2019 Educational Course \n",
    "\n",
    "### Thomas Funck\n",
    "\n",
    "### McGill University\n",
    "\n",
    "### **Contact**: email: [tffunck@gmail.com](mailto:tffunck@gmail.com) , Twitter: [@tffunck](https://twitter.com/tffunck)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring basic options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minc_keras import create_dir_verbose, setup_dirs\n",
    "from utils import *\n",
    "\n",
    "### Set input and label string\n",
    "input_str='pet.mnc' \n",
    "label_str='dtissue.mnc'\n",
    "\n",
    "### Set filename for .csv that will store data frame \n",
    "images_fn='data.csv'\n",
    "\n",
    "### Set source directory from which data will be read\n",
    "source_dir=\"/data1/users/tfunck/pet/data_ses/\"\n",
    "\n",
    "### Set the target directory where output results will be saved\n",
    "target_dir=\"/data1/users/tfunck/pet/results\"\n",
    "\n",
    "### Set raiots for train/validation/test\n",
    "ratios=[0.7,0.15]\n",
    "\n",
    "### By default we set clobber to False so that we don't overwrite existing files\n",
    "### Feel free to change if needed\n",
    "clobber=True\n",
    "\n",
    "### Size of batches that will be passed to model. The default 2 makes it easy\n",
    "batch_size=2\n",
    "\n",
    "### Image dimensions. We are slicing the 3D images into 2D slices. This serves to augment the data\n",
    "### and make training faster\n",
    "image_dim=2\n",
    "\n",
    "### Output activation function\n",
    "activation_output=\"softmax\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is just a little housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_dirs()  \n",
    "### Set filename for .csv file that will contain info about input images\n",
    "images_fn = set_model_name(images_fn, report_dir, '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize input and label images into train/validate/test splits\n",
    "#### One of the hard parts of doing deep learning in practice is organizing your data.\n",
    "#### The following section is a bit of complicated because it involves organizing the input and label files into \n",
    "#### a data frame and assigning them to a train/validate/test splits.\n",
    "\n",
    "### Example data set\n",
    "#### Train : Data on which network will be trained\n",
    "#### Validation : Data on which network is evaluated between iterations\n",
    "#### Test : Data for final evaluation of network\n",
    "#### 16 images \n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/splits_a_1.png?raw=1)\n",
    "### Multiple splits possible, depends on amount and structure of data\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/splits_a.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splits with correlated data\n",
    "#### 16 images\n",
    "#### Data can be correlated\n",
    "#### For example, your images may have been collected from different centers or on different scanners\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/splits_b_1.png?raw=1)\n",
    "\n",
    "#### Example: 3 subtypes of images (e.g. scanner type)\n",
    "#### ***Don't*** create splits with only \n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/splits_b_2.png?raw=1)\n",
    "#### ***Do*** balance your subtypes between splits\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/splits_b_3.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splits with correlated data and repeated subjects\n",
    "#### 3 images x 5 subjects\n",
    "#### 3 subtypes of images (e.g. scanner type)\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/splits_c.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/tfunck/minc_keras/blob/master/images/splits_c_3.png?raw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : expected/real ratio = 70.00 / 70.29\n",
      "validate : expected/real ratio = 15.00 / 15.22\n",
      "Saving train images: 180 / 194\r"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "[images, data] = prepare_data(source_dir, data_dir, report_dir, input_str, label_str, ratios, batch_size,feature_dim, images_fn,  clobber=clobber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a U-NET in Keras\n",
    "\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/unet.png?raw=1)\n",
    "\n",
    "Ronneberger, Fischer, and Brox. 2015.\"U-net: Convolutional networks for biomedical image segmentation.\" International Conference on Medical image computing and computer-assisted intervention. https://arxiv.org/abs/1505.04597"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ### 1) Define architecture of neural network\n",
    "    Y_validate=np.load(data[\"validate_y_fn\"]+'.npy')\n",
    "    nlabels=len(np.unique(Y_validate))#Number of unique labels in the labeled images\n",
    "    \n",
    "    img_rows=image_dim[1]\n",
    "    img_cols=image_dim[2]\n",
    "    nMLP=16\n",
    "    nRshp=int(sqrt(nMLP))\n",
    "    nUpSm=int(image_dim[0]/nRshp)\n",
    "    image = Input(shape=(image_dim[1], image_dim[2],1))\n",
    "    \n",
    "    BN1 = BatchNormalization()(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    conv1 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(BN1)\n",
    "    conv1 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    conv2 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(pool1)\n",
    "    conv2 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    conv3 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(pool2)\n",
    "    conv3 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    conv4 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(pool3)\n",
    "    conv4 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    conv5 = Convolution2D(512, 3, 3, activation='relu', border_mode='same')(pool4)\n",
    "    conv5 = Convolution2D(512, 3, 3, activation='relu', border_mode='same')(conv5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    up6 = merge([UpSampling2D(size=(2, 2))(conv5), conv4], mode='concat', concat_axis=3)\n",
    "    conv6 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(up6)\n",
    "    conv6 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(conv6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    conv6_up = UpSampling2D(size=(2, 2))(conv6)\n",
    "    conv6_pad = ZeroPadding2D( ((1,0),(1,0)) )(conv6_up)\n",
    "    up7 = merge([conv6_pad, conv3], mode='concat', concat_axis=3)\n",
    "    conv7 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(up7)\n",
    "    conv7 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(conv7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    up8 = merge([UpSampling2D(size=(2, 2))(conv7), conv2], mode='concat', concat_axis=3)\n",
    "    conv8 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(up8)\n",
    "    conv8 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(conv8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    up9 = merge([UpSampling2D(size=(2, 2))(conv8), conv1], mode='concat', concat_axis=3)\n",
    "    conv9 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(up9)\n",
    "    conv9 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(conv9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    conv10 = Convolution2D(nlabels, 1, 1, activation=activation)(conv9)\n",
    "\n",
    "    model = keras.models.Model(input=[image], output=conv10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2) Train network on data\n",
    "model_fn =set_model_name(model_fn, model_dir)\n",
    "history_fn = splitext(model_fn)[0] + '_history.json'\n",
    "\n",
    "print( 'Model:', model_fn)\n",
    "if not exists(model_fn) or clobber:\n",
    "    #If model_fn does not exist, or user wishes to write over (clobber) existing model\n",
    "    #then train a new model and save it\n",
    "    \n",
    "    #Load input images for training data\n",
    "    X_train=np.load(data[\"train_x_fn\"]+'.npy')\n",
    "    #Load labels for training data\n",
    "    Y_train=np.load(data[\"train_y_fn\"]+'.npy')\n",
    "    #Load input images for validation data set\n",
    "    X_validate=np.load(data[\"validate_x_fn\"]+'.npy')\n",
    "    #Set compiler\n",
    "    ada = keras.optimizers.Adam(0.0001)\n",
    "    #Create filename to save checkpoints \n",
    "    checkpoint_fn = splitext(model_name)[0]+\"_checkpoint-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "    #Create checkpoint callback function for model\n",
    "    checkpoint = ModelCheckpoint(checkpoint_fn, monitor='val_loss', verbose=0, save_best_only=True, mode='max')\n",
    "    #Compile the model\n",
    "    model.compile(loss = loss, optimizer=ada,metrics=[metric] )\n",
    "    \n",
    "  \n",
    "    print(\"Running with\", nb_epoch)\n",
    "    #\n",
    "    if loss in categorical_functions : \n",
    "        #Convert training data to categorical format\n",
    "        Y_train = to_categorical(Y_train, num_classes=nlabels)\n",
    "        #Convert validation data to categorical format\n",
    "        Y_validate = to_categorical(Y_validate, num_classes=nlabels)\n",
    "    #Fit model\n",
    "    history = model.fit([X_train],Y_train,  validation_data=([X_validate], Y_validate), epochs = nb_epoch,callbacks=[ checkpoint])\n",
    "    #save model   \n",
    "    model.save(model_name)\n",
    "\n",
    "    with open(history_fn, 'w+') as fp: json.dump(history.history, fp)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ### 3) Evaluate model on test data\n",
    "    model = load_model(model_fn)\n",
    "    X_test=np.load(data[\"test_x_fn\"]+'.npy')\n",
    "    Y_test=np.load(data[\"test_y_fn\"]+'.npy')\n",
    "    if loss in categorical_functions :\n",
    "        Y_test=to_categorical(Y_test)\n",
    "    test_score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "    print('Test: Loss=', test_score[0], 'Metric=', test_score[1])\n",
    "    #np.savetxt(report_dir+os.sep+'model_evaluate.csv', np.array(test_score) )\n",
    "\n",
    "    ### 4) Produce prediction\n",
    "    #predict(model_fn, validate_dir, data_dir, images_fn, images_to_predict=images_to_predict, category=\"validate\", verbose=verbose)\n",
    "    #predict(model_fn, train_dir, data_dir, images_fn, images_to_predict=images_to_predict, category=\"train\", verbose=verbose)\n",
    "    predict(model_fn, test_dir, data_dir, images_fn, loss, images_to_predict=images_to_predict, category=\"test\", verbose=verbose)\n",
    "    plot_loss(metric, history_fn, model_fn, report_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
