{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a--rFzYazTo2"
   },
   "source": [
    "# Introduction to Brain Segmentation with Keras\n",
    "\n",
    "# ***MAIN 2019 Educational Course***\n",
    "\n",
    "## Thomas Funck\n",
    "\n",
    "## McGill University\n",
    "\n",
    "## **Contact**: email: [tffunck@gmail.com](mailto:tffunck@gmail.com) , Twitter: [@tffunck](https://twitter.com/tffunck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "OPVCbLjaj0An",
    "outputId": "73e1fa15-456a-44af-a446-e786bb44738d"
   },
   "outputs": [],
   "source": [
    "#Download repository\n",
    "!git clone https://github.com/tfunck/minc_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "65Sg-1ESzv8O"
   },
   "outputs": [],
   "source": [
    "#Switch dir\n",
    "import os\n",
    "if os.getcwd() != '/content/minc_keras/' : os.chdir('/content/minc_keras')\n",
    "\n",
    "#Unzip\n",
    "!tar -jxvf data/output.tar.bz2 &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "colab_type": "code",
    "id": "bxS3dqQLaaiH",
    "outputId": "2c19974b-ac9c-4513-a635-2f458e719d93"
   },
   "outputs": [],
   "source": [
    "#Import minc_keras\n",
    "import minc_keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F5dHDJJBzTo4"
   },
   "source": [
    "# ***Outline***\n",
    "# 1. Basic Concepts\n",
    "## --1.1 Introductory Examples\n",
    "## --1.2 Parameters\n",
    "## --1.3 Receptive Field\n",
    "## --1.4 Dilations\n",
    "## --1.5 Cross-validation\n",
    "## --1.6 Final activation functions\n",
    "## --1.7 Cross-entropy\n",
    "# 2. Simple Networks\n",
    "## --2.1 Base\n",
    "## --2.2 Over-fitting\n",
    "## --2.3 Regularization with Drop-out\n",
    "## --2.4 Using dilations\n",
    "# 3. U-Net\n",
    "## --3.1 Max-pool \n",
    "## --3.2 Upsampling\n",
    "## --3.3 Concatenating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rp0rzqT5zTo5"
   },
   "source": [
    "# Example of a simple convolutional neural network\n",
    "## 1 Layer, 3 Kernels of 3x3 size\n",
    "\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/conv_1.png?raw=1)\n",
    "\n",
    "## ***Keras Output:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "yWuBDhTYzTo6",
    "outputId": "fb9d17d2-b9ac-4189-d7e1-f30990949ead"
   },
   "outputs": [],
   "source": [
    "minc_keras.minc_keras(source_dir=\"output\", target_dir=\"results\", input_str=\"T1w_anat_rsl.mnc\",\\\n",
    "           label_str=\"variant-seg_rsl.mnc\", ratios=[0.7,0.15,0.15], nK=\"3\", kernel_size=3,\\\n",
    "           model_type=\"custom\", nb_epoch=0, make_model_only=True, verbose=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SEejHgeS_hSX"
   },
   "source": [
    "```\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_1 (InputLayer)         (None, 110, 92, 1)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_1 (Conv2D)            (None, 110, 92, 3)        30        \n",
    "_________________________________________________________________\n",
    "dropout_1 (Dropout)          (None, 110, 92, 3)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_2 (Conv2D)            (None, 110, 92, 3)        12        \n",
    "=================================================================\n",
    "Total params: 42\n",
    "Trainable params: 42\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "None\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hqV5xJPY_fcr"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6hydP1gbzTo8"
   },
   "source": [
    "# Adding in a second layer\n",
    "## 2 Layers, 3 Kernels of 3x3 size\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/conv_2.png?raw=1)\n",
    "## ***Keras Output:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "gWIM3Ra-zTo8",
    "outputId": "db332050-7bce-4029-e2d1-8436fdf01e85"
   },
   "outputs": [],
   "source": [
    "minc_keras.minc_keras(source_dir=\"data/output\", target_dir=\"results\", input_str=\"T1w_anat_rsl.mnc\",\\\n",
    "           label_str=\"variant-seg_rsl.mnc\", ratios=[0.7,0.15,0.15], nK=\"3,3\", kernel_size=3,\\\n",
    "           model_type=\"custom\", nb_epoch=0, make_model_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I9R1zJD8zTo_"
   },
   "source": [
    "# Adding in a second layer\n",
    "## 3 Layers, 3 Kernels of 3x3 size\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/conv_3.png?raw=1)\n",
    "## ***Keras Output:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "colab_type": "code",
    "id": "n2nAiMxUzTo_",
    "outputId": "d2a3d9e2-9305-49d5-ceba-c09cd219df8d"
   },
   "outputs": [],
   "source": [
    "minc_keras.minc_keras(source_dir=\"data/output\", target_dir=\"results\", input_str=\"T1w_anat_rsl.mnc\",\\\n",
    "           label_str=\"variant-seg_rsl.mnc\", ratios=[0.7,0.15,0.15], nK=\"3,3,3\", kernel_size=3,\\\n",
    "           model_type=\"custom\", nb_epoch=0, make_model_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QSxAll0fzTpB"
   },
   "source": [
    "# How many parameters in a convolutional layer?\n",
    "## $N_{parameters} = N_{kernels} \\times Kernel_{Dimension1} \\times Kernel_{Dimension2}  + N_{kernels}$\n",
    "### ***Example: Layer with 3 kernels of 3x3 size + 1 bias parameter per kernel = 3x3x3+3 = 30 parameters*** \n",
    "\n",
    "\n",
    "```\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_2 (InputLayer)         (None, 110, 92, 1)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_3 (Conv2D)            (None, 110, 92, 3)        30        \n",
    "_________________________________________________________________\n",
    "dropout_2 (Dropout)          (None, 110, 92, 3)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_4 (Conv2D)            (None, 110, 92, 3)        84        \n",
    "_________________________________________________________________\n",
    "dropout_3 (Dropout)          (None, 110, 92, 3)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_5 (Conv2D)            (None, 110, 92, 3)        84        \n",
    "_________________________________________________________________\n",
    "dropout_4 (Dropout)          (None, 110, 92, 3)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_6 (Conv2D)            (None, 110, 92, 3)        12        \n",
    "=================================================================\n",
    "Total params: 210\n",
    "Trainable params: 210\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "None\n",
    "```\n",
    "# Parameters in ***conv2d_3***  and ***conv2d_4*** are different? What gives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K9nEml0-zTpB"
   },
   "source": [
    "![](https://github.com/tfunck/minc_keras/blob/master/images/depth_0_1.png?raw=1)\n",
    "## Layer with N kernels with turn a 2D (X,Y) input into a 3D (X,Y,N) array\n",
    "## --> 3x3 kernels for next layer must have dimensions of (3,3,N) to convolve (X,Y,N) image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GSqejpTPzTpD"
   },
   "source": [
    "![](https://github.com/tfunck/minc_keras/blob/master/images/depth_0_2.png?raw=1)\n",
    "## $N_{parameters} = N_{kernels} \\times Kernel_{Dimension1} \\times Kernel_{Dimension2} \\times Input_{Channels}  + N_{kernels}$\n",
    "### ***Example: Layer with 3 3x3 kernels and 3 channels + 3 bias parameters = 3x3x3x3+3 = 84 parameters*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1zXZTwrJzTpD"
   },
   "source": [
    "# How to transform multi-channel layers so that final output layer matches labels? \n",
    "\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/conv_1.png?raw=1)\n",
    "\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/depth_1.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EaK2zUn0zTpE"
   },
   "source": [
    "![](https://github.com/tfunck/minc_keras/blob/master/images/depth_2.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B921eE6KzTpF"
   },
   "source": [
    "# Receptive Field\n",
    "\n",
    "## 3 Layers, 16 Kernels of 3x3 size\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/conv_3.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/receptive_field_0.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/tfunck/minc_keras/blob/master/images/receptive_field_1.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dilations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-4yD2CyZzTpL"
   },
   "source": [
    "# __Spliting Data for Cross Validation__\n",
    "## 1) Uncorrelated data\n",
    "## ***Train*** : Data on which network will be trained\n",
    "## ***Validation*** : Data on which network is evaluated between iterations\n",
    "## ***Test*** : Data for final evaluation of network\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/splits_a_1.png?raw=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "amJEatoDzTpM"
   },
   "source": [
    "## 2) Correlated data\n",
    "\n",
    "### Example: T1 MRI images collected from on different scanners\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/splits_b_1.png?raw=1)\n",
    "\n",
    "### ***Don't*** create splits with only very unbalanced splits:\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/splits_b_2.png?raw=1)\n",
    "### ***Do*** balance your subtypes between splits:\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/splits_b_3.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vare5DRUzTpN"
   },
   "source": [
    "## 3) Splits with correlated data and repeated subjects\n",
    "### 3 images x 5 subjects\n",
    "### 3 subtypes of images (e.g. scanner type)\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/splits_c.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZB0ZXe4DzTpF"
   },
   "source": [
    "# Training a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "vDqzkarSzTpF",
    "outputId": "c8a847cf-f298-462f-ffc3-2481e3a21650"
   },
   "outputs": [],
   "source": [
    "minc_keras.minc_keras(source_dir=\"data/output\", target_dir=\"results\", input_str=\"T1w_anat_rsl.mnc\",\\\n",
    "           label_str=\"variant-seg_rsl.mnc\", ratios=[0.7,0.15,0.15], nK=\"16,16,16\", kernel_size=3,\\\n",
    "           model_type=\"custom\", nb_epoch=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1_J1YOL_Lw05"
   },
   "source": [
    "## Understanding Keras output\n",
    "```\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_7 (InputLayer)         (None, 110, 92, 1)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_16 (Conv2D)           (None, 110, 92, 16)       160       \n",
    "_________________________________________________________________\n",
    "dropout_10 (Dropout)         (None, 110, 92, 16)       0         \n",
    "_________________________________________________________________\n",
    "conv2d_17 (Conv2D)           (None, 110, 92, 16)       2320      \n",
    "_________________________________________________________________\n",
    "dropout_11 (Dropout)         (None, 110, 92, 16)       0         \n",
    "_________________________________________________________________\n",
    "conv2d_18 (Conv2D)           (None, 110, 92, 16)       2320      \n",
    "_________________________________________________________________\n",
    "dropout_12 (Dropout)         (None, 110, 92, 16)       0         \n",
    "_________________________________________________________________\n",
    "conv2d_19 (Conv2D)           (None, 110, 92, 3)        51        \n",
    "=================================================================\n",
    "Total params: 4,851\n",
    "Trainable params: 4,851\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "None\n",
    "Model: results/model/model.hdf5\n",
    "Running with 5\n",
    "(11598, 110, 92, 1) (11598, 110, 92, 3) (2556, 110, 92, 1) (2556, 110, 92, 3)\n",
    "Train on 11598 samples, validate on 2556 samples\n",
    "Epoch 1/5\n",
    "11598/11598 [==============================] - 355s 31ms/step - loss: 0.7399 - categorical_accuracy: 0.8595 - val_loss: 0.2688 - val_categorical_accuracy: 0.8872\n",
    "Epoch 2/5\n",
    "11598/11598 [==============================] - 353s 30ms/step - loss: 0.2238 - categorical_accuracy: 0.9010 - val_loss: 0.2193 - val_categorical_accuracy: 0.8986\n",
    "Epoch 3/5\n",
    "11598/11598 [==============================] - 352s 30ms/step - loss: 0.1969 - categorical_accuracy: 0.9111 - val_loss: 0.1999 - val_categorical_accuracy: 0.9083\n",
    "Epoch 4/5\n",
    "11598/11598 [==============================] - 350s 30ms/step - loss: 0.1807 - categorical_accuracy: 0.9204 - val_loss: 0.1863 - val_categorical_accuracy: 0.9184\n",
    "Epoch 5/5\n",
    "11598/11598 [==============================] - 352s 30ms/step - loss: 0.1689 - categorical_accuracy: 0.9272 - val_loss: 0.1745 - val_categorical_accuracy: 0.9243\n",
    "2478/2478 [==============================] - 21s 9ms/step\n",
    "Test: Loss= 0.16739090936765064 Metric= 0.9286423676239087\n",
    "No images were specified for prediction.\n",
    "Model training plot written to  results/report//model_loss_plot.png\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying over-fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [92, 110, 92]\n",
      "2 [92, 110, 92]\n",
      "N Labels: 3\n",
      "Drop out: 0\n",
      "Number of Dilations: None\n",
      "Activation hidden: relu\n",
      "Activation output: sigmoid\n",
      "Layer: 0 128 5 1\n",
      "Layer: 1 128 5 1\n",
      "Layer: 2 128 5 1\n",
      "Layer: 3 128 5 1\n",
      "Layer: 4 128 5 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 110, 92, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 110, 92, 128)      3328      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 110, 92, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 110, 92, 128)      409728    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 110, 92, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 110, 92, 128)      409728    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 110, 92, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 110, 92, 128)      409728    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 110, 92, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 110, 92, 128)      409728    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 110, 92, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 110, 92, 3)        387       \n",
      "=================================================================\n",
      "Total params: 1,642,627\n",
      "Trainable params: 1,642,627\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: results/model/overfit.hdf5\n",
      "Train on 11645 samples, validate on 2473 samples\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9969a55b9033>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mminc_keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mminc_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminc_keras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"data/output\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"results\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"T1w_anat_rsl.mnc\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"overfit.hdf5\"\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0mlabel_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"variant-seg_rsl.mnc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratios\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.35\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.35\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"128,128,128,128,128\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"custom\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/neuro/projects/minc_keras/minc_keras.py\u001b[0m in \u001b[0;36mminc_keras\u001b[0;34m(source_dir, target_dir, input_str, label_str, ratios, feature_dim, batch_size, nb_epoch, images_to_predict, clobber, model_fn, model_type, images_fn, nK, n_dil, kernel_size, drop_out, loss, activation_hidden, activation_output, metric, pad_base, verbose, make_model_only)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mY_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_y_fn\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mX_validate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"validate_x_fn\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile_and_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_validate\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mY_validate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m### 3) Evaluate model on test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neuro/projects/minc_keras/make_and_run_model.py\u001b[0m in \u001b[0;36mcompile_and_run\u001b[0;34m(model, model_name, history_fn, X_train, Y_train, X_validate, Y_validate, nb_epoch, nlabels, metric, loss, lr, verbose)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_validate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_validate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0;31m#save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import minc_keras\n",
    "minc_keras.minc_keras(source_dir=\"data/output\", target_dir=\"results\", input_str=\"T1w_anat_rsl.mnc\",model_fn=\"overfit.hdf5\",\\\n",
    "           label_str=\"variant-seg_rsl.mnc\", ratios=[0.3,0.35,0.35], nK=\"128,128,128,128,128\", kernel_size=5,\\\n",
    "           model_type=\"custom\", nb_epoch=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using regularization to control over-fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "9qhOKYbtEsT1",
    "outputId": "9aa35c1c-3d19-495a-ce76-29872e1fe16b"
   },
   "outputs": [],
   "source": [
    "minc_keras.minc_keras(source_dir=\"output/\", target_dir=\"results\", input_str=\"T1w_anat_rsl.mnc\",\\\n",
    "           label_str=\"variant-seg_rsl.mnc\", ratios=[0.7,0.15,0.15], nK=\"16,16,16\", kernel_size=3,\\\n",
    "           model_type=\"custom\", drop_out=0.25, nb_epoch=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding dilations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Fo61_R0GYoq"
   },
   "outputs": [],
   "source": [
    "minc_keras.minc_keras(source_dir=\"output\", target_dir=\"results\", input_str=\"T1w_anat_rsl.mnc\",model_fn=\"drop_out.hdf5\",\\\n",
    "                      label_str=\"variant-seg_rsl.mnc\", ratios=[0.7,0.15,0.15], nK=\"16,16,16\", n_dil=\"2,2,2\",\\\n",
    "                      kernel_size=3, model_type=\"custom\", drop_out=0.25, nb_epoch=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D8VmKHg4zTpH"
   },
   "source": [
    "## Configuring basic options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sUFWF1w_zTpJ"
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import numpy as np\n",
    "from minc_keras import *\n",
    "### Set input and label string\n",
    "input_str='pet.mnc' \n",
    "label_str='dtissue.mnc'\n",
    "\n",
    "### Set filename for .csv that will store data frame \n",
    "images_fn='data.csv'\n",
    "\n",
    "### Set source directory from which data will be read\n",
    "source_dir=\"/data1/users/tfunck/pet/data_ses/\"\n",
    "\n",
    "### Set the target directory where output results will be saved\n",
    "target_dir=\"/data1/users/tfunck/pet/results\"\n",
    "\n",
    "### Set raiots for train/validation/test\n",
    "ratios=[0.7,0.15]\n",
    "\n",
    "### By default we set clobber to False so that we don't overwrite existing files\n",
    "### Feel free to change if needed\n",
    "clobber=True\n",
    "\n",
    "### Size of batches that will be passed to model. The default 2 makes it easy\n",
    "batch_size=2\n",
    "\n",
    "### Image dimensions. We are slicing the 3D images into 2D slices. This serves to augment the data\n",
    "### and make training faster\n",
    "image_dim=2\n",
    "\n",
    "setup_dirs()  \n",
    "\n",
    "### Set filename for .csv file that will contain info about input images\n",
    "images_fn = set_model_name(images_fn, report_dir, '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5u7QfjeKzTpN"
   },
   "source": [
    "![](https://github.com/tfunck/minc_keras/blob/master/images/splits_c_3.png?raw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SqBWn-PmzTpO"
   },
   "outputs": [],
   "source": [
    "[images, data] = prepare_data(source_dir, data_dir, report_dir, input_str, label_str, ratios, batch_size,feature_dim, images_fn,  clobber=clobber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rGkJHbkPzTpQ"
   },
   "source": [
    "## Building a U-NET in Keras\n",
    "\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/unet.png?raw=1)\n",
    "\n",
    "Ronneberger, Fischer, and Brox. 2015.\"U-net: Convolutional networks for biomedical image segmentation.\" International Conference on Medical image computing and computer-assisted intervention. https://arxiv.org/abs/1505.04597"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0SDJ5RvOzTpQ"
   },
   "outputs": [],
   "source": [
    "    ### 1) Define architecture of neural network\n",
    "    Y_validate=np.load(data[\"validate_y_fn\"]+'.npy')\n",
    "    nlabels=len(np.unique(Y_validate))#Number of unique labels in the labeled images\n",
    "    \n",
    "    img_rows=image_dim[1]\n",
    "    img_cols=image_dim[2]\n",
    "    nMLP=16\n",
    "    nRshp=int(sqrt(nMLP))\n",
    "    nUpSm=int(image_dim[0]/nRshp)\n",
    "    image = Input(shape=(image_dim[1], image_dim[2],1))\n",
    "    \n",
    "    BN1 = BatchNormalization()(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0lS5aBHfzTpS"
   },
   "outputs": [],
   "source": [
    "    conv1 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(BN1)\n",
    "    conv1 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EMOPQmvKzTpU"
   },
   "source": [
    "# Max Pool\n",
    "\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/max_pool.png?raw=1)\n",
    "\n",
    "## Becareful: 2x2 max pool reduces image dimensions by 2\n",
    "## --> Applying max pool 4 times reduces image dimensions by 2^4\n",
    "## --> Make sure image can be evenly divided, otherwise end up with problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2SEtPk_uzTpU"
   },
   "outputs": [],
   "source": [
    "    conv2 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(pool1)\n",
    "    conv2 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hn5NNyCEzTpW"
   },
   "outputs": [],
   "source": [
    "    conv3 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(pool2)\n",
    "    conv3 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0R-_cVwvzTpY"
   },
   "outputs": [],
   "source": [
    "    conv4 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(pool3)\n",
    "    conv4 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cf7dXkBHzTpb"
   },
   "outputs": [],
   "source": [
    "    conv5 = Convolution2D(512, 3, 3, activation='relu', border_mode='same')(pool4)\n",
    "    conv5 = Convolution2D(512, 3, 3, activation='relu', border_mode='same')(conv5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8hXeLMq5zTpe"
   },
   "outputs": [],
   "source": [
    "    up6 = merge([UpSampling2D(size=(2, 2))(conv5), conv4], mode='concat', concat_axis=3)\n",
    "    conv6 = Convolution2D(512, 3, 3, activation='relu', border_mode='same')(up6)\n",
    "    conv6 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(conv6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7THYQRXSzTpi"
   },
   "source": [
    "# ***Upsampling***\n",
    "\n",
    "# 1. Transpose Convolution\n",
    "\n",
    "## $M \\circledast k = N$, where $k$ is a $(x,x)$ max pool filter, $M$ is a $(y,y)$ 2D array\n",
    "## $N$ is a downsampled 2D array with dimensions $(i,i)$, where $i = y-x+1$\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/upsample_1.png?raw=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S8_6X7rKzTpi"
   },
   "source": [
    "## The 2D array can be \"flattened\" into a $(i^2,1)$ vector 1D $m$ \n",
    "## The convolution kernel, $k$, can also be expressed as a $(i^2,y^2)$ matrix $K$  \n",
    "## --> $K m = n$, where $(i^2,y^2) \\times (y^2,1) = (i^2,1)$ and $n$ is a $(y^2,1)$ 1D vector \n",
    "\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/upsample_2.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LyjQqzQvzTpi"
   },
   "source": [
    "### If we take the transpose of the matrix $K$, $K^T$ to create a $(y^2,i^2)$ matrix\n",
    "### We can write $K^T N = M_1$,  $(y^2,i^2) \\times (i^2,1) = (y^2,1)$ which can then be converted back into a $(y,y)$ 2D array\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/upsample_3.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GN2IedTVzTpj"
   },
   "source": [
    "# 2. Interpolation\n",
    "\n",
    "## Simply use interpolation (e.g., nearest neighbour) to higher resolution\n",
    "## Does not require extra parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3vdanc3YzTpk"
   },
   "source": [
    "# Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QUEgJX0tzTpl"
   },
   "outputs": [],
   "source": [
    "    conv6_up = UpSampling2D(size=(2, 2))(conv6)\n",
    "    conv6_pad = ZeroPadding2D( ((1,0),(1,0)) )(conv6_up)\n",
    "    up7 = merge([conv6_pad, conv3], mode='concat', concat_axis=3)\n",
    "    conv7 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(up7)\n",
    "    conv7 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(conv7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T9pxn42wzTpl"
   },
   "outputs": [],
   "source": [
    "    up8 = merge([UpSampling2D(size=(2, 2))(conv7), conv2], mode='concat', concat_axis=3)\n",
    "    conv8 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(up8)\n",
    "    conv8 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(conv8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pY-AJDGBzTpo"
   },
   "outputs": [],
   "source": [
    "    up9 = merge([UpSampling2D(size=(2, 2))(conv8), conv1], mode='concat', concat_axis=3)\n",
    "    conv9 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(up9)\n",
    "    conv9 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(conv9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7fVqv-YHzTpp"
   },
   "source": [
    "# ***Choosing final activation function***\n",
    "## Last activation function is used to compare output of network to labels\n",
    "## Type of activation function depends on purpose of network\n",
    "## Classification often means mapping real valued inputs to integer outputs\n",
    "## --> Shouldn't use ReLu for classification \n",
    "\n",
    "\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/pet_mask.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qkr3FXMDzTpq"
   },
   "source": [
    "## Binary classification\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/sigmoid.png?raw=1)\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/sigmoid_eq.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QnZ70smkzTpq"
   },
   "source": [
    "## Multi-category classification\n",
    "### Generalization of sigmoid function\n",
    "### Creates a pseudo-probability distribution for each label: values between 0 and 1 and sum to 1\n",
    "### Label with highest probability is attributed to pixel \n",
    "\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/multi_sigmoid_eq.png?raw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y30hs3e2zTpr"
   },
   "outputs": [],
   "source": [
    "### Output activation function\n",
    "activation_output=\"softmax\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uo_puMm2zTpt"
   },
   "outputs": [],
   "source": [
    "    conv10 = Convolution2D(nlabels, 1, 1, activation=activation)(conv9)\n",
    "\n",
    "    model = keras.models.Model(input=[image], output=conv10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uPeNV6NWzTpu"
   },
   "outputs": [],
   "source": [
    "### 2) Train network on data\n",
    "model_fn =set_model_name(model_fn, model_dir)\n",
    "history_fn = splitext(model_fn)[0] + '_history.json'\n",
    "\n",
    "print( 'Model:', model_fn)\n",
    "if not exists(model_fn) or clobber:\n",
    "    #If model_fn does not exist, or user wishes to write over (clobber) existing model\n",
    "    #then train a new model and save it\n",
    "    \n",
    "    #Load input images for training data\n",
    "    X_train=np.load(data[\"train_x_fn\"]+'.npy')\n",
    "    #Load labels for training data\n",
    "    Y_train=np.load(data[\"train_y_fn\"]+'.npy')\n",
    "    #Load input images for validation data set\n",
    "    X_validate=np.load(data[\"validate_x_fn\"]+'.npy')\n",
    "    #Set compiler\n",
    "    ada = keras.optimizers.Adam(0.0001)\n",
    "    #Create filename to save checkpoints \n",
    "    checkpoint_fn = splitext(model_name)[0]+\"_checkpoint-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "    #Create checkpoint callback function for model\n",
    "    checkpoint = ModelCheckpoint(checkpoint_fn, monitor='val_loss', verbose=0, save_best_only=True, mode='max')\n",
    "    #Compile the model\n",
    "    model.compile(loss = loss, optimizer=ada,metrics=[metric] )\n",
    "    \n",
    "  \n",
    "    print(\"Running with\", nb_epoch)\n",
    "    #\n",
    "    if loss in categorical_functions : \n",
    "        #Convert training data to categorical format\n",
    "        Y_train = to_categorical(Y_train, num_classes=nlabels)\n",
    "        #Convert validation data to categorical format\n",
    "        Y_validate = to_categorical(Y_validate, num_classes=nlabels)\n",
    "    #Fit model\n",
    "    history = model.fit([X_train],Y_train,  validation_data=([X_validate], Y_validate), epochs = nb_epoch,callbacks=[ checkpoint])\n",
    "    #save model   \n",
    "    model.save(model_name)\n",
    "\n",
    "    with open(history_fn, 'w+') as fp: json.dump(history.history, fp)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lzd3DkZFzTpw"
   },
   "outputs": [],
   "source": [
    "    ### 3) Evaluate model on test data\n",
    "    model = load_model(model_fn)\n",
    "    X_test=np.load(data[\"test_x_fn\"]+'.npy')\n",
    "    Y_test=np.load(data[\"test_y_fn\"]+'.npy')\n",
    "    if loss in categorical_functions :\n",
    "        Y_test=to_categorical(Y_test)\n",
    "    test_score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "    print('Test: Loss=', test_score[0], 'Metric=', test_score[1])\n",
    "    #np.savetxt(report_dir+os.sep+'model_evaluate.csv', np.array(test_score) )\n",
    "\n",
    "    ### 4) Produce prediction\n",
    "    #predict(model_fn, validate_dir, data_dir, images_fn, images_to_predict=images_to_predict, category=\"validate\", verbose=verbose)\n",
    "    #predict(model_fn, train_dir, data_dir, images_fn, images_to_predict=images_to_predict, category=\"train\", verbose=verbose)\n",
    "    predict(model_fn, test_dir, data_dir, images_fn, loss, images_to_predict=images_to_predict, category=\"test\", verbose=verbose)\n",
    "    plot_loss(metric, history_fn, model_fn, report_dir)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "main2019.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
