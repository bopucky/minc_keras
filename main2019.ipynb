{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Brain Segmentation with Keras\n",
    "\n",
    "# ***MAIN 2019 Educational Course***\n",
    "\n",
    "## Thomas Funck\n",
    "\n",
    "## McGill University\n",
    "\n",
    "## **Contact**: email: [tffunck@gmail.com](mailto:tffunck@gmail.com) , Twitter: [@tffunck](https://twitter.com/tffunck)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Outline***\n",
    "# _1. Basic Concepts_\n",
    "### --1.1 Introductory Examples\n",
    "### --1.2 Parameters\n",
    "### --1.3 Receptive Field\n",
    "### --1.4 Cross-validation\n",
    "### --1.5 Final activation functions\n",
    "# _2. Simple Networks_\n",
    "### --2.1 Base\n",
    "### --2.2 Drop-out\n",
    "### --2.3 Dilations\n",
    "# _3. U-Net_\n",
    "### --3.1 Max-pool \n",
    "### --3.2 Upsampling\n",
    "### --3.3 Concatenating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of a simple convolutional neural network\n",
    "## 1 Layer, 3 Kernels of 3x3 size\n",
    "\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/conv_1.png?raw=1)\n",
    "\n",
    "## ***Keras Output:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named keras",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-46ced0a22ae1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mminc_keras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mminc_keras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"data/output\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"results\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"T1w_anat_rsl.mnc\"\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0mlabel_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"variant-seg_rsl.mnc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratios\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"custom\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_model_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/projects/minc_keras/minc_keras.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#local modules defined in current project\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmake_and_run_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpredict\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mprepare_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/projects/minc_keras/make_and_run_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling3D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolutional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv3D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named keras"
     ]
    }
   ],
   "source": [
    "from minc_keras import *\n",
    "minc_keras(source_dir=\"data/output\", target_dir=\"results\", input_str=\"T1w_anat_rsl.mnc\",\\\n",
    "           label_str=\"variant-seg_rsl.mnc\", ratios=[0.7,0.15,0.15], nK=\"3\", kernel_size=3,\\\n",
    "           model_type=\"custom\", nb_epoch=0, make_model_only=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding in a second layer\n",
    "## 2 Layers, 3 Kernels of 3x3 size\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/conv_2.png?raw=1)\n",
    "## ***Keras Output:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minc_keras(source_dir=\"data/output\", target_dir=\"results\", input_str=\"T1w_anat_rsl.mnc\",\\\n",
    "           label_str=\"variant-seg_rsl.mnc\", ratios=[0.7,0.15,0.15], nK=\"3,3\", kernel_size=3,\\\n",
    "           model_type=\"custom\", nb_epoch=0, make_model_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding in a second layer\n",
    "## 3 Layers, 3 Kernels of 3x3 size\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/conv_3.png?raw=1)\n",
    "## ***Keras Output:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minc_keras(source_dir=\"data/output\", target_dir=\"results\", input_str=\"T1w_anat_rsl.mnc\",\\\n",
    "           label_str=\"variant-seg_rsl.mnc\", ratios=[0.7,0.15,0.15], nK=\"3,3,3\", kernel_size=3,\\\n",
    "           model_type=\"custom\", nb_epoch=0, make_model_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many parameters in a convolutional layer?\n",
    "## $N_{parameters} = N_{kernels} \\times Kernel_{Dimension1} \\times Kernel_{Dimension2}  + N_{kernels}$\n",
    "### ***Example: Layer with 3 kernels of 3x3 size + 1 bias parameter per kernel = 3x3x3+3 = 30 parameters*** \n",
    "\n",
    "\n",
    "```\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_2 (InputLayer)         (None, 110, 92, 1)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_3 (Conv2D)            (None, 110, 92, 3)        30        \n",
    "_________________________________________________________________\n",
    "dropout_2 (Dropout)          (None, 110, 92, 3)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_4 (Conv2D)            (None, 110, 92, 3)        84        \n",
    "_________________________________________________________________\n",
    "dropout_3 (Dropout)          (None, 110, 92, 3)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_5 (Conv2D)            (None, 110, 92, 3)        84        \n",
    "_________________________________________________________________\n",
    "dropout_4 (Dropout)          (None, 110, 92, 3)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_6 (Conv2D)            (None, 110, 92, 3)        12        \n",
    "=================================================================\n",
    "Total params: 210\n",
    "Trainable params: 210\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "None\n",
    "```\n",
    "# Parameters in ***conv2d_3***  and ***conv2d_4*** are different? What gives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/tfunck/minc_keras/blob/master/images/depth_0_1.png?raw=1)\n",
    "## Layer with N kernels with turn a 2D (X,Y) input into a 3D (X,Y,N) array\n",
    "## --> 3x3 kernels for next layer must have dimensions of (3,3,N) to convolve (X,Y,N) image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/tfunck/minc_keras/blob/master/images/depth_0_2.png?raw=1)\n",
    "## $N_{parameters} = N_{kernels} \\times Kernel_{Dimension1} \\times Kernel_{Dimension2} \\times Input_{Channels}  + N_{kernels}$\n",
    "### ***Example: Layer with 3 3x3 kernels and 3 channels + 3 bias parameters = 3x3x3x3+3 = 84 parameters*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to transform multi-channel layers so that final output layer matches labels? \n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/depth_1.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/tfunck/minc_keras/blob/master/images/depth_2.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Receptive Field\n",
    "## Receptive field: \n",
    "## ***\"The receptive field of an individual sensory neuron is the particular region of the sensory space (e.g., the body surface, or the visual field) in which a stimulus will modify the firing of that neuron.\"***\n",
    "### https://en.wikipedia.org/wiki/Receptive_field\n",
    "## Adding more layers increases the receptive field\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/receptive_field_0.png?raw=1)\n",
    "\n",
    "\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/receptive_field_1.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Spliting Data for Cross Validation__\n",
    "## 1) Uncorrelated data\n",
    "## ***Train*** : Data on which network will be trained\n",
    "## ***Validation*** : Data on which network is evaluated between iterations\n",
    "## ***Test*** : Data for final evaluation of network\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/splits_a_1.png?raw=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Correlated data\n",
    "\n",
    "### Example: T1 MRI images collected from on different scanners\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/splits_b_1.png?raw=1)\n",
    "\n",
    "### ***Don't*** create splits with only very unbalanced splits:\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/splits_b_2.png?raw=1)\n",
    "### ***Do*** balance your subtypes between splits:\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/splits_b_3.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Splits with correlated data and repeated subjects\n",
    "### 3 images x 5 subjects\n",
    "### 3 subtypes of images (e.g. scanner type)\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/splits_c.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Choosing final activation function***\n",
    "## Last activation function is used to compare output of network to labels\n",
    "## Type of activation function depends on purpose of network\n",
    "## Classification often means mapping real valued inputs to integer outputs\n",
    "## --> Shouldn't use ReLu for classification \n",
    "\n",
    "\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/pet_mask.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/sigmoid.png?raw=1)\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/sigmoid_eq.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-category classification\n",
    "### Generalization of sigmoid function\n",
    "### Creates a pseudo-probability distribution for each label: values between 0 and 1 and sum to 1\n",
    "### Label with highest probability is attributed to pixel \n",
    "\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/multi_sigmoid_eq.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Training a simple model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minc_keras(source_dir=\"data/output\", target_dir=\"results\", input_str=\"T1w_anat_rsl.mnc\",\\\n",
    "           label_str=\"variant-seg_rsl.mnc\", ratios=[0.7,0.15,0.15], nK=\"16,16,16\", kernel_size=3,\\\n",
    "           model_type=\"custom\", nb_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minc_keras(source_dir=\"data/output\", target_dir=\"results\", input_str=\"T1w_anat_rsl.mnc\",\\\n",
    "           label_str=\"variant-seg_rsl.mnc\", ratios=[0.7,0.15,0.15], nK=\"16,16,16\", dropout=0.25, kernel_size=3,\\\n",
    "           model_type=\"custom\", nb_epoch=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring basic options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import numpy as np\n",
    "from minc_keras import *\n",
    "### Set input and label string\n",
    "input_str='pet.mnc' \n",
    "label_str='dtissue.mnc'\n",
    "\n",
    "### Set filename for .csv that will store data frame \n",
    "images_fn='data.csv'\n",
    "\n",
    "### Set source directory from which data will be read\n",
    "source_dir=\"/data1/users/tfunck/pet/data_ses/\"\n",
    "\n",
    "### Set the target directory where output results will be saved\n",
    "target_dir=\"/data1/users/tfunck/pet/results\"\n",
    "\n",
    "### Set raiots for train/validation/test\n",
    "ratios=[0.7,0.15]\n",
    "\n",
    "### By default we set clobber to False so that we don't overwrite existing files\n",
    "### Feel free to change if needed\n",
    "clobber=True\n",
    "\n",
    "### Size of batches that will be passed to model. The default 2 makes it easy\n",
    "batch_size=2\n",
    "\n",
    "### Image dimensions. We are slicing the 3D images into 2D slices. This serves to augment the data\n",
    "### and make training faster\n",
    "image_dim=2\n",
    "\n",
    "setup_dirs()  \n",
    "\n",
    "### Set filename for .csv file that will contain info about input images\n",
    "images_fn = set_model_name(images_fn, report_dir, '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/tfunck/minc_keras/blob/master/images/splits_c_3.png?raw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[images, data] = prepare_data(source_dir, data_dir, report_dir, input_str, label_str, ratios, batch_size,feature_dim, images_fn,  clobber=clobber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a U-NET in Keras\n",
    "\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/unet.png?raw=1)\n",
    "\n",
    "Ronneberger, Fischer, and Brox. 2015.\"U-net: Convolutional networks for biomedical image segmentation.\" International Conference on Medical image computing and computer-assisted intervention. https://arxiv.org/abs/1505.04597"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    ### 1) Define architecture of neural network\n",
    "    Y_validate=np.load(data[\"validate_y_fn\"]+'.npy')\n",
    "    nlabels=len(np.unique(Y_validate))#Number of unique labels in the labeled images\n",
    "    \n",
    "    img_rows=image_dim[1]\n",
    "    img_cols=image_dim[2]\n",
    "    nMLP=16\n",
    "    nRshp=int(sqrt(nMLP))\n",
    "    nUpSm=int(image_dim[0]/nRshp)\n",
    "    image = Input(shape=(image_dim[1], image_dim[2],1))\n",
    "    \n",
    "    BN1 = BatchNormalization()(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    conv1 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(BN1)\n",
    "    conv1 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max Pool\n",
    "\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/max_pool.png?raw=1)\n",
    "\n",
    "## Becareful: 2x2 max pool reduces image dimensions by 2\n",
    "## --> Applying max pool 4 times reduces image dimensions by 2^4\n",
    "## --> Make sure image can be evenly divided, otherwise end up with problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    conv2 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(pool1)\n",
    "    conv2 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    conv3 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(pool2)\n",
    "    conv3 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    conv4 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(pool3)\n",
    "    conv4 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    conv5 = Convolution2D(512, 3, 3, activation='relu', border_mode='same')(pool4)\n",
    "    conv5 = Convolution2D(512, 3, 3, activation='relu', border_mode='same')(conv5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    up6 = merge([UpSampling2D(size=(2, 2))(conv5), conv4], mode='concat', concat_axis=3)\n",
    "    conv6 = Convolution2D(512, 3, 3, activation='relu', border_mode='same')(up6)\n",
    "    conv6 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(conv6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Upsampling***\n",
    "\n",
    "# 1. Transpose Convolution\n",
    "\n",
    "## $M \\circledast k = N$, where $k$ is a $(x,x)$ max pool filter, $M$ is a $(y,y)$ 2D array\n",
    "## $N$ is a downsampled 2D array with dimensions $(i,i)$, where $i = y-x+1$\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/upsample_1.png?raw=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The 2D array can be \"flattened\" into a $(i^2,1)$ vector 1D $m$ \n",
    "## The convolution kernel, $k$, can also be expressed as a $(i^2,y^2)$ matrix $K$  \n",
    "## --> $K m = n$, where $(i^2,y^2) \\times (y^2,1) = (i^2,1)$ and $n$ is a $(y^2,1)$ 1D vector \n",
    "\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/upsample_2.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we take the transpose of the matrix $K$, $K^T$ to create a $(y^2,i^2)$ matrix\n",
    "### We can write $K^T N = M_1$,  $(y^2,i^2) \\times (i^2,1) = (y^2,1)$ which can then be converted back into a $(y,y)$ 2D array\n",
    "![](https://github.com/tfunck/minc_keras/blob/master/images/upsample_3.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Interpolation\n",
    "\n",
    "## Simply use interpolation (e.g., nearest neighbour) to higher resolution\n",
    "## Does not require extra parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    conv6_up = UpSampling2D(size=(2, 2))(conv6)\n",
    "    conv6_pad = ZeroPadding2D( ((1,0),(1,0)) )(conv6_up)\n",
    "    up7 = merge([conv6_pad, conv3], mode='concat', concat_axis=3)\n",
    "    conv7 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(up7)\n",
    "    conv7 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(conv7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    up8 = merge([UpSampling2D(size=(2, 2))(conv7), conv2], mode='concat', concat_axis=3)\n",
    "    conv8 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(up8)\n",
    "    conv8 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(conv8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    up9 = merge([UpSampling2D(size=(2, 2))(conv8), conv1], mode='concat', concat_axis=3)\n",
    "    conv9 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(up9)\n",
    "    conv9 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(conv9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Output activation function\n",
    "activation_output=\"softmax\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    conv10 = Convolution2D(nlabels, 1, 1, activation=activation)(conv9)\n",
    "\n",
    "    model = keras.models.Model(input=[image], output=conv10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 2) Train network on data\n",
    "model_fn =set_model_name(model_fn, model_dir)\n",
    "history_fn = splitext(model_fn)[0] + '_history.json'\n",
    "\n",
    "print( 'Model:', model_fn)\n",
    "if not exists(model_fn) or clobber:\n",
    "    #If model_fn does not exist, or user wishes to write over (clobber) existing model\n",
    "    #then train a new model and save it\n",
    "    \n",
    "    #Load input images for training data\n",
    "    X_train=np.load(data[\"train_x_fn\"]+'.npy')\n",
    "    #Load labels for training data\n",
    "    Y_train=np.load(data[\"train_y_fn\"]+'.npy')\n",
    "    #Load input images for validation data set\n",
    "    X_validate=np.load(data[\"validate_x_fn\"]+'.npy')\n",
    "    #Set compiler\n",
    "    ada = keras.optimizers.Adam(0.0001)\n",
    "    #Create filename to save checkpoints \n",
    "    checkpoint_fn = splitext(model_name)[0]+\"_checkpoint-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "    #Create checkpoint callback function for model\n",
    "    checkpoint = ModelCheckpoint(checkpoint_fn, monitor='val_loss', verbose=0, save_best_only=True, mode='max')\n",
    "    #Compile the model\n",
    "    model.compile(loss = loss, optimizer=ada,metrics=[metric] )\n",
    "    \n",
    "  \n",
    "    print(\"Running with\", nb_epoch)\n",
    "    #\n",
    "    if loss in categorical_functions : \n",
    "        #Convert training data to categorical format\n",
    "        Y_train = to_categorical(Y_train, num_classes=nlabels)\n",
    "        #Convert validation data to categorical format\n",
    "        Y_validate = to_categorical(Y_validate, num_classes=nlabels)\n",
    "    #Fit model\n",
    "    history = model.fit([X_train],Y_train,  validation_data=([X_validate], Y_validate), epochs = nb_epoch,callbacks=[ checkpoint])\n",
    "    #save model   \n",
    "    model.save(model_name)\n",
    "\n",
    "    with open(history_fn, 'w+') as fp: json.dump(history.history, fp)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    ### 3) Evaluate model on test data\n",
    "    model = load_model(model_fn)\n",
    "    X_test=np.load(data[\"test_x_fn\"]+'.npy')\n",
    "    Y_test=np.load(data[\"test_y_fn\"]+'.npy')\n",
    "    if loss in categorical_functions :\n",
    "        Y_test=to_categorical(Y_test)\n",
    "    test_score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "    print('Test: Loss=', test_score[0], 'Metric=', test_score[1])\n",
    "    #np.savetxt(report_dir+os.sep+'model_evaluate.csv', np.array(test_score) )\n",
    "\n",
    "    ### 4) Produce prediction\n",
    "    #predict(model_fn, validate_dir, data_dir, images_fn, images_to_predict=images_to_predict, category=\"validate\", verbose=verbose)\n",
    "    #predict(model_fn, train_dir, data_dir, images_fn, images_to_predict=images_to_predict, category=\"train\", verbose=verbose)\n",
    "    predict(model_fn, test_dir, data_dir, images_fn, loss, images_to_predict=images_to_predict, category=\"test\", verbose=verbose)\n",
    "    plot_loss(metric, history_fn, model_fn, report_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
